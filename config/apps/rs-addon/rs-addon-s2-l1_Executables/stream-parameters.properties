### Compliance to integration procedure v1.10 applied
##    Kafka configuration
#       Set replication count 
app.*.spring.cloud.stream.kafka.binder.replicationFactor=3
app.*.spring.cloud.stream.kafka.streams.binder.replicationFactor=3
app.*.spring.cloud.stream.kafka.streams.binder.configuration.replication.factor=3

#       Set retention for all topic 
#app.*.spring.cloud.stream.kafka.bindings.input.consumer.topic.properties.retention.ms=2678400000
#app.*.spring.cloud.stream.kafka.bindings.input.consumer.s2-l1-part1.s2-l1-filter.properties.retention.ms=2678400000
#app.*.spring.cloud.stream.kafka.bindings.input.consumer.s2-l1-part1.pw-l1s.properties.retention.ms=2678400000
#app.*.spring.cloud.stream.kafka.bindings.input.consumer.s2-l1-part1.ew-l1sa.properties.retention.ms=2678400000
#app.*.spring.cloud.stream.kafka.bindings.input.consumer.s2-l1-part3.pw-l1c.properties.retention.ms=2678400000
#app.*.spring.cloud.stream.kafka.bindings.input.consumer.s2-l1-job.properties.retention.ms=2678400000

#       Set partition count for all topics
app.pw-l1s.spring.cloud.stream.kafka.binder.autoAddPartitions=true
app.pw-l1s.spring.cloud.stream.kafka.binder.minPartitionCount=30
app.pw-l1c.spring.cloud.stream.kafka.binder.autoAddPartitions=true
app.pw-l1c.spring.cloud.stream.kafka.binder.minPartitionCount=30

#       Set Lag balancing
app.pw-l1s.spring.cloud.stream.kafka.bindings.input.producer.configuration.partitioner.class=esa.s1pdgs.cpoc.message.kafka.LagBasedPartitioner
app.pw-l1s.spring.cloud.stream.kafka.binder.producerProperties.lag-based-partitioner.delay-seconds=30
app.pw-l1s.spring.cloud.stream.kafka.binder.producerProperties.lag-based-partitioner.consumer-group=s2-l1-ew-l1sa
app.pw-l1s.spring.cloud.stream.kafka.binder.producerProperties.lag-based-partitioner.topics-with-priority.s2-l1-part1.pw-l1s=1

app.ew-l1sa.spring.cloud.stream.kafka.bindings.input.producer.configuration.partitioner.class=esa.s1pdgs.cpoc.message.kafka.LagBasedPartitioner
app.ew-l1sa.spring.cloud.stream.kafka.binder.producerProperties.lag-based-partitioner.delay-seconds=30
app.ew-l1sa.spring.cloud.stream.kafka.binder.producerProperties.lag-based-partitioner.consumer-group=s2-l1-ew-l1sb
app.ew-l1sa.spring.cloud.stream.kafka.binder.producerProperties.lag-based-partitioner.topics-with-priority.s2-l1-part1.ew-l1sa=1

app.ew-l1sb.spring.cloud.stream.kafka.bindings.input.producer.configuration.partitioner.class=esa.s1pdgs.cpoc.message.kafka.LagBasedPartitioner
app.ew-l1sb.spring.cloud.stream.kafka.binder.producerProperties.lag-based-partitioner.delay-seconds=30
app.ew-l1sb.spring.cloud.stream.kafka.binder.producerProperties.lag-based-partitioner.consumer-group=s2-l1-ew-l1ab
app.ew-l1sb.spring.cloud.stream.kafka.binder.producerProperties.lag-based-partitioner.topics-with-priority.s2-l1-job=1

app.pw-l1c.spring.cloud.stream.kafka.bindings.input.producer.configuration.partitioner.class=esa.s1pdgs.cpoc.message.kafka.LagBasedPartitioner
app.pw-l1c.spring.cloud.stream.kafka.binder.producerProperties.lag-based-partitioner.delay-seconds=30
app.pw-l1c.spring.cloud.stream.kafka.binder.producerProperties.lag-based-partitioner.consumer-group=s2-l1-ew-l1c
app.pw-l1c.spring.cloud.stream.kafka.binder.producerProperties.lag-based-partitioner.topics-with-priority.s2-l1-part3.pw-l1c=1

#       Set Long Processing parameters
app.ew-l1sa.spring.cloud.stream.kafka.binder.consumer-properties.max.poll.interval.ms=28800000
app.ew-l1sa.spring.cloud.stream.kafka.binder.consumer-properties.max.poll.records=1
app.ew-l1sb.spring.cloud.stream.kafka.binder.consumer-properties.max.poll.interval.ms=14400000
app.ew-l1sb.spring.cloud.stream.kafka.binder.consumer-properties.max.poll.records=1
app.ew-l1ab.spring.cloud.stream.kafka.binder.consumer-properties.max.poll.interval.ms=28800000
app.ew-l1ab.spring.cloud.stream.kafka.binder.consumer-properties.max.poll.records=1
app.ew-l1c.spring.cloud.stream.kafka.binder.consumer-properties.max.poll.interval.ms=14400000
app.ew-l1c.spring.cloud.stream.kafka.binder.consumer-properties.max.poll.records=1

######################## Deployer #################################################################

deployer.*.kubernetes.image-pull-policy=Always
deployer.*.kubernetes.namespace=processing

deployer.*.kubernetes.liveness-probe-delay=10
deployer.*.kubernetes.liveness-probe-path=/actuator/health/liveness
deployer.*.kubernetes.liveness-probe-period=60
deployer.*.kubernetes.liveness-probe-port=8080
deployer.*.kubernetes.liveness-probe-timeout=60
deployer.*.kubernetes.readiness-probe-delay=60
deployer.*.kubernetes.readiness-probe-path=/actuator/health/readiness
deployer.*.kubernetes.readiness-probe-period=60
deployer.*.kubernetes.readiness-probe-port=8080
deployer.*.kubernetes.readiness-probe-timeout=20
deployer.*.kubernetes.max-terminated-error-restarts=3

deployer.pw-l1s.kubernetes.requests.memory=1000Mi
deployer.pw-l1s.kubernetes.limits.memory=4000Mi
deployer.pw-l1s.kubernetes.requests.cpu=300m
deployer.pw-l1s.kubernetes.limits.cpu=2000m

deployer.pw-l1c.kubernetes.requests.memory=1000Mi
deployer.pw-l1c.kubernetes.limits.memory=4000Mi
deployer.pw-l1c.kubernetes.requests.cpu=300m
deployer.pw-l1c.kubernetes.limits.cpu=2000m

deployer.ew-l1sa.kubernetes.requests.memory=40000Mi
deployer.ew-l1sa.kubernetes.limits.memory=48000Mi
deployer.ew-l1sa.kubernetes.requests.cpu=3000m
deployer.ew-l1sa.kubernetes.limits.cpu=8000m


deployer.ew-l1sb.kubernetes.requests.memory=2000Mi
deployer.ew-l1sb.kubernetes.limits.memory=80000Mi
# We will set request.cpu to 6 cpu (instead of 1 cpu) to avoid collocalisation of EW POD on same node. 
# A better approach would be to set quota on disk usage (with a PVC or other solution). 
deployer.ew-l1sb.kubernetes.requests.cpu=6000m
deployer.ew-l1sb.kubernetes.limits.cpu=8000m


deployer.ew-l1ab.kubernetes.requests.memory=48000Mi
deployer.ew-l1ab.kubernetes.limits.memory=80000Mi
deployer.ew-l1ab.kubernetes.requests.cpu=3000m
deployer.ew-l1ab.kubernetes.limits.cpu=8000m


deployer.ew-l1c.kubernetes.requests.memory=24000Mi
deployer.ew-l1c.kubernetes.limits.memory=32000Mi
deployer.ew-l1c.kubernetes.requests.cpu=3000m
deployer.ew-l1c.kubernetes.limits.cpu=8000m


###   For filter
deployer.s2-l1-filter.kubernetes.requests.cpu=160m
deployer.s2-l1-filter.kubernetes.limits.cpu=300m
deployer.s2-l1-filter.kubernetes.requests.memory=512Mi
deployer.s2-l1-filter.kubernetes.limits.memory=600Mi

#  Version
app.*.common.rsChainVersion=1.8.0
version.pw-l1s=1.8.0
version.ew-l1sa=1.8.0
version.ew-l1sb=1.8.0
version.ew-l1ab=1.8.0
version.pw-l1c=1.8.0
version.ew-l1c=1.8.0
version.s2-l1-filter=3.2.1


####################### App specific #############################################################



### Catalog config
app.pw-l1s.catalog.url=http://rs-metadata-catalog-searchcontroller-svc.processing.svc.cluster.local:8080
app.pw-l1s.catalog.timeout=5

### Chain config
app.*.chain.name=s2-l1
app.*.chain.version=1.8.0

### Mongo config
app.pw-l1s.mongo.authenticationDatabase=admin
app.pw-l1s.mongo.database=s2-l1-pw-l1s
app.pw-l1s.mongo.port=27017
app.pw-l1s.mongo.host=mongodb-0.mongodb-headless.database.svc.cluster.local

### Obs properties
app.*.obs.endpoint=https://oss.eu-west-0.prod-cloud-ocb.orange-business.com
app.*.obs.region=eu-west-0
app.*.obs.maxConcurrency=50
app.*.obs.maxThroughput=10
app.*.obs.minimumPartSize=5
app.*.obs.maxRetries=3
app.*.obs.downloadTimeout=15
app.*.obs.uploadTimeout=15
app.*.obs.bucket.auxBucket=ops-rs-s2-aux
app.*.obs.bucket.sessionBucket=ops-rs-session-files
app.*.obs.bucket.sadBucket=ops-rs-s2-sadata
app.*.obs.bucket.hktmBucket=ops-rs-s2-hktm
app.*.obs.bucket.l0DSBucket=ops-rs-s2-l0-ds
app.*.obs.bucket.l0GRBucket=ops-rs-s2-l0-gr
app.*.obs.bucket.l1DSBucket=ops-rs-s2-l1-ds
app.*.obs.bucket.l1GRBucket=ops-rs-s2-l1-gr
app.*.obs.bucket.l1TLBucket=ops-rs-s2-l1-tl
app.*.obs.bucket.l1TCBucket=ops-rs-s2-l1-tc

### Cleanup config
app.*.cleanup.localEnabled=true
app.*.cleanup.sharedEnabled=true
app.*.cleanup.hours=144

### Kafka Config
app.*.spring.kafka.bootstrap-servers=kafka-cluster-kafka-bootstrap.infra.svc.cluster.local:9092
app.*.spring.cloud.stream.kafka.binder.brokers=kafka-cluster-kafka-bootstrap.infra.svc.cluster.local:9092
app.*.spring.cloud.stream.kafka.binder.auto-create-topics=true
app.*.spring.cloud.stream.kafka.bindings.input.consumer.enable-dlq=true
app.*.spring.cloud.stream.kafka.bindings.input.consumer.dlq-name=error-warning
app.*.spring.cloud.stream.kafka.bindings.input.consumer.poll-timeout=5
app.*.spring.cloud.stream.bindings.input.consumer.max-attempts=1

app.pw-l1s.spring.cloud.stream.bindings.input.group=s2-l1-pw-l1s
app.ew-l1sa.spring.cloud.stream.bindings.input.group=s2-l1-ew-l1sa
app.ew-l1sb.spring.cloud.stream.bindings.input.group=s2-l1-ew-l1sb
app.ew-l1ab.spring.cloud.stream.bindings.input.group=s2-l1-ew-l1ab
app.pw-l1c.spring.cloud.stream.bindings.input.group=s2-l1-pw-l1c
app.ew-l1c.spring.cloud.stream.bindings.input.group=s2-l1-ew-l1c

### Preparation worker L1S
app.pw-l1s.spring.profiles.active=prod
deployer.pw-l1s.kubernetes.secret-refs=[ s2-l1-mongo, s2-l1-obs ]
deployer.pw-l1s.kubernetes.podSecurityContext={runAsUser: 1000}
deployer.pw-l1s.kubernetes.volume-mounts=[ { name: shared, mountPath: '/shared' } ]
deployer.pw-l1s.kubernetes.volumes=[ { name: shared, persistentVolumeClaim: { claimName: 's2-l1-shared', storageClassName: 'ceph-fs' } } ]

### Preparation worker L1C
app.pw-l1c.spring.profiles.active=prod
deployer.pw-l1c.kubernetes.secret-refs=[ s2-l1-mongo, s2-l1-obs ]
deployer.pw-l1c.kubernetes.podSecurityContext={runAsUser: 1000}
deployer.pw-l1c.kubernetes.volume-mounts=[ { name: shared, mountPath: '/shared' } ]
deployer.pw-l1c.kubernetes.volumes=[ { name: shared, persistentVolumeClaim: { claimName: 's2-l1-shared', storageClassName: 'ceph-fs' } } ]

### Execution workers
app.*.ps2.sharedFolderRoot=/shared
app.*.ps2.demFolderRoot=/dem
app.*.ps2.gridFolderRoot=/grid
app.*.ps2.maxParallelTasks=8

### Execution worker L1SA
app.ew-l1sa.spring.profiles.active=prod
app.ew-l1sa.ps2.killTimeout=21600
deployer.ew-l1sa.kubernetes.secret-refs=s2-l1-obs
deployer.ew-l1sa.kubernetes.podSecurityContext={runAsUser: 1000}
deployer.ew-l1sa.kubernetes.volume-mounts=[ { name: shared, mountPath: '/shared' }, { name: dem, mountPath: '/dem' }, { name: grid, mountPath: '/grid' } ]
deployer.ew-l1sa.kubernetes.volumes=[ { name: shared, persistentVolumeClaim: { claimName: 's2-l1-shared', storageClassName: 'ceph-fs' } }, { name: dem, persistentVolumeClaim: { claimName: 's2-dem', storageClassName: 'ceph-fs' } }, { name: grid, persistentVolumeClaim: { claimName: 'gri-s2-l1', storageClassName: 'ceph-fs' } } ]

### Execution worker L1SB
app.ew-l1sb.spring.profiles.active=prod
app.ew-l1sb.ps2.killTimeout=21600
deployer.ew-l1sb.kubernetes.secret-refs=s2-l1-obs
deployer.ew-l1sb.kubernetes.podSecurityContext={runAsUser: 1000}
deployer.ew-l1sb.kubernetes.volume-mounts=[ { name: shared, mountPath: '/shared' }, { name: dem, mountPath: '/dem' }, { name: grid, mountPath: '/grid' } ]
deployer.ew-l1sb.kubernetes.volumes=[ { name: shared, persistentVolumeClaim: { claimName: 's2-l1-shared', storageClassName: 'ceph-fs' } }, { name: dem, persistentVolumeClaim: { claimName: 's2-dem', storageClassName: 'ceph-fs' } }, { name: grid, persistentVolumeClaim: { claimName: 'gri-s2-l1', storageClassName: 'ceph-fs' } } ]

### Execution worker L1AB
app.ew-l1ab.spring.profiles.active=prod
app.ew-l1ab.ps2.killTimeout=14400
deployer.ew-l1ab.kubernetes.secret-refs=s2-l1-obs
deployer.ew-l1ab.kubernetes.podSecurityContext={runAsUser: 1000}
deployer.ew-l1ab.kubernetes.volume-mounts=[ { name: shared, mountPath: '/shared' }, { name: dem, mountPath: '/dem' }, { name: grid, mountPath: '/grid' } ]
deployer.ew-l1ab.kubernetes.volumes=[ { name: shared, persistentVolumeClaim: { claimName: 's2-l1-shared', storageClassName: 'ceph-fs' } }, { name: dem, persistentVolumeClaim: { claimName: 's2-dem', storageClassName: 'ceph-fs' } }, { name: grid, persistentVolumeClaim: { claimName: 'gri-s2-l1', storageClassName: 'ceph-fs' } } ]

### Execution worker L1C
app.ew-l1c.spring.profiles.active=prod
deployer.ew-l1c.kubernetes.secret-refs=s2-l1-obs
deployer.ew-l1c.kubernetes.podSecurityContext={runAsUser: 1000}
deployer.ew-l1c.kubernetes.volume-mounts=[ { name: shared, mountPath: '/shared' }, { name: dem, mountPath: '/dem' }, { name: grid, mountPath: '/grid' } ]
deployer.ew-l1c.kubernetes.volumes=[ { name: shared, persistentVolumeClaim: { claimName: 's2-l1-shared', storageClassName: 'ceph-fs' } }, { name: dem, persistentVolumeClaim: { claimName: 's2-dem', storageClassName: 'ceph-fs' } }, { name: grid, persistentVolumeClaim: { claimName: 'gri-s2-l1', storageClassName: 'ceph-fs' } } ]

###Filter
app.s2-l1-filter.spring.cloud.stream.bindings.input.group=s2-l1-filter
app.s2-l1-filter.expression=((payload.additionalFields == null) || (payload.additionalFields.f5 != 'true')) && (     (payload.missionId=='S2' and (payload.productFamily=='S2_L0_DS' or payload.productFamily=='S2_L0_GR' or payload.productFamily=='S2_AUX'))     )
app.s2-l1-filter.spring.cloud.stream.kafka.bindings.input.consumer.enableDlq=false
app.s2-l1-filter.spring.cloud.stream.kafka.bindings.input.consumer.configuration.max.poll.records=50
app.s2-l1-filter.spring.cloud.stream.kafka.bindings.input.consumer.configuration.max.poll.interval.ms=600000

deployer.s2-l1-filter.kubernetes.affinity.nodeAffinity={ requiredDuringSchedulingIgnoredDuringExecution: { nodeSelectorTerms: [ { matchExpressions: [ { key: 'node-role.kubernetes.io/processing', operator: 'In', values: 'common'}]}]}}
deployer.pw-l1s.kubernetes.affinity.nodeAffinity={ requiredDuringSchedulingIgnoredDuringExecution: { nodeSelectorTerms: [ { matchExpressions: [ { key: 'node-role.kubernetes.io/processing', operator: 'In', values: 'common'}]}]}}
deployer.pw-l1c.kubernetes.affinity.nodeAffinity={ requiredDuringSchedulingIgnoredDuringExecution: { nodeSelectorTerms: [ { matchExpressions: [ { key: 'node-role.kubernetes.io/processing', operator: 'In', values: 'common'}]}]}}
deployer.ew-l1sa.kubernetes.affinity.nodeAffinity={ requiredDuringSchedulingIgnoredDuringExecution: { nodeSelectorTerms: [ { matchExpressions: [ { key: 'node-role.kubernetes.io/processing', operator: 'In', values: 's2-l1sa'}]}]}}
deployer.ew-l1sb.kubernetes.affinity.nodeAffinity={ requiredDuringSchedulingIgnoredDuringExecution: { nodeSelectorTerms: [ { matchExpressions: [ { key: 'node-role.kubernetes.io/processing', operator: 'In', values: 'common'}]}]}}
deployer.ew-l1ab.kubernetes.affinity.nodeAffinity={ requiredDuringSchedulingIgnoredDuringExecution: { nodeSelectorTerms: [ { matchExpressions: [ { key: 'node-role.kubernetes.io/processing', operator: 'In', values: 'common'}]}]}}
deployer.ew-l1c.kubernetes.affinity.nodeAffinity={ requiredDuringSchedulingIgnoredDuringExecution: { nodeSelectorTerms: [ { matchExpressions: [ { key: 'node-role.kubernetes.io/processing', operator: 'In', values: 'common'}]}]}}

deployer.s2-l1-filter.kubernetes.tolerations=[{key: 'node-role.kubernetes.io/processing', effect: 'NoSchedule'}]
deployer.pw-l1s.kubernetes.tolerations=[{key: 'node-role.kubernetes.io/processing', effect: 'NoSchedule'}]
deployer.pw-l1c.kubernetes.tolerations=[{key: 'node-role.kubernetes.io/processing', effect: 'NoSchedule'}]
deployer.ew-l1sa.kubernetes.tolerations=[{key: 'node-role.kubernetes.io/S2L1', effect: 'NoSchedule'}]
deployer.ew-l1sb.kubernetes.tolerations=[{key: 'node-role.kubernetes.io/processing', effect: 'NoSchedule'}]
deployer.ew-l1ab.kubernetes.tolerations=[{key: 'node-role.kubernetes.io/processing', effect: 'NoSchedule'}]
deployer.ew-l1c.kubernetes.tolerations=[{key: 'node-role.kubernetes.io/processing', effect: 'NoSchedule'}]
