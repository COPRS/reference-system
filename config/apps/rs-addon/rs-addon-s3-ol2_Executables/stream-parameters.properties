# General Application properties
app.*.spring.kafka.bootstrap-servers=kafka-cluster-kafka-bootstrap.infra.svc.cluster.local:9092
app.*.main.banner-mode=off
app.*.management.endpoints.web.exposure.include=*
app.*.management.endpoint.health.show-details=always

app.preparation-worker.logging.config=/log/log4j2.yml
app.housekeep.logging.config=/log/log4j2.yml
app.execution-worker.logging.config=/log/log4j2.yml


### Compliance to integration procedure v1.13 applied
# Configure the topic replicas
app.*.spring.cloud.stream.kafka.binder.replicationFactor=3
app.*.spring.cloud.stream.kafka.streams.binder.replicationFactor=3
app.*.spring.cloud.stream.kafka.streams.binder.configuration.replication.factor=3

# Configure retention for all topic 
# app.*.spring.cloud.stream.kafka.bindings.input.consumer.topic.properties.retention.ms=2678400000
# app.*.spring.cloud.stream.kafka.bindings.input.consumer.s3-ol2-nrt-part1.message-filter.properties.retention.ms=2678400000
# app.*.spring.cloud.stream.kafka.bindings.input.consumer.s3-ol2-nrt-part1.preparation-worker.properties.retention.ms=2678400000
# app.*.spring.cloud.stream.kafka.bindings.input.consumer.s3-ol2-nrt-part2.time.properties.retention.ms=2678400000

# Configure the topic partition count
app.preparation-worker.spring.cloud.stream.kafka.binder.autoAddPartitions=true
app.preparation-worker.spring.cloud.stream.kafka.binder.minPartitionCount=30

# set Lag Balancing
app.preparation-worker.spring.cloud.stream.kafka.bindings.input.producer.configuration.partitioner.class=esa.s1pdgs.cpoc.message.kafka.LagBasedPartitioner
app.preparation-worker.spring.cloud.stream.kafka.binder.producerProperties.lag-based-partitioner.delay-seconds=30
app.preparation-worker.spring.cloud.stream.kafka.binder.producerProperties.lag-based-partitioner.consumer-group=s3-ol2-nrt-part1
app.preparation-worker.spring.cloud.stream.kafka.binder.producerProperties.lag-based-partitioner.topics-with-priority.s3-ol2-nrt-part1.preparation-worker=1

# Set Long processing parameters
app.execution-worker.spring.cloud.stream.kafka.bindings.input.consumer.configuration.max.poll.records=1
app.execution-worker.spring.cloud.stream.kafka.bindings.input.consumer.configuration.max.poll.interval.ms=3600000

# Limit and request (* for message-filter and time)
deployer.message-filter.kubernetes.requests.memory=512Mi
deployer.message-filter.kubernetes.requests.cpu=160m
deployer.message-filter.kubernetes.limits.memory=600Mi
deployer.message-filter.kubernetes.limits.cpu=300m

deployer.time.kubernetes.requests.memory=512Mi
deployer.time.kubernetes.requests.cpu=160m
deployer.time.kubernetes.limits.memory=600Mi
deployer.time.kubernetes.limits.cpu=300m

deployer.preparation-worker.kubernetes.requests.memory=390Mi
deployer.preparation-worker.kubernetes.requests.cpu=100m
deployer.preparation-worker.kubernetes.limits.memory=1560Mi
deployer.preparation-worker.kubernetes.limits.cpu=500m

deployer.housekeep.kubernetes.requests.memory=390Mi
deployer.housekeep.kubernetes.requests.cpu=100m
deployer.housekeep.kubernetes.limits.memory=1560Mi
deployer.housekeep.kubernetes.limits.cpu=500m

deployer.execution-worker.kubernetes.requests.memory=6000Mi
deployer.execution-worker.kubernetes.requests.cpu=7000m
deployer.execution-worker.kubernetes.limits.memory=15000Mi
deployer.execution-worker.kubernetes.limits.cpu=7000m

## Workaround mode enabled (US #643)
app.preparation-worker.metadata.valintersectnoduplicatesworkaround=true

# Version
app.*.common.rsChainName=S3-OL2-NRT
app.*.common.rsChainVersion=1.14.0
version.message-filter=3.2.1
version.housekeep=1.14.0
version.time=3.2.1
version.preparation-worker=1.14.0
version.execution-worker=1.14.0

# Error Management
app.*.spring.cloud.stream.bindings.input.consumer.maxAttempts=1
app.message-filter.spring.cloud.stream.kafka.bindings.input.consumer.enableDlq=false
app.housekeep.spring.cloud.stream.kafka.bindings.input.consumer.enableDlq=true
app.time.spring.cloud.stream.kafka.bindings.input.consumer.enableDlq=true
app.preparation-worker.spring.cloud.stream.kafka.bindings.input.consumer.enableDlq=true
app.execution-worker.spring.cloud.stream.kafka.bindings.input.consumer.enableDlq=true
app.*.spring.cloud.stream.kafka.bindings.input.consumer.dlqName=error-warning

# Custom Application properties
## Filter
app.message-filter.filter.function.expression=((payload.additionalFields == null) || (payload.additionalFields.f5 != 'true')) && (    ((payload.productFamily == 'S3_L1_NRT') && (payload.keyObjectStorage matches '^S3\\w{2}(OL_1_EFR|OL_1_ERR)___.*')) || ((payload.productFamily == 'S3_AUX') && (payload.keyObjectStorage matches '^S3\\w{2}(AX___(BB2|FRO|FPO|OSF)|OL_2_(PCP|PPP|WVP|ACP|OCP|VGP|CLP))_AX.*'))   )
app.message-filter.spring.cloud.stream.kafka.bindings.input.consumer.configuration.max.poll.records=50
app.message-filter.spring.cloud.stream.kafka.bindings.input.consumer.configuration.max.poll.interval.ms=600000

## Preparation Worker
app.preparation-worker.spring.cloud.stream.kafka.bindings.input.consumer.configuration.max.poll.records=1
app.preparation-worker.spring.cloud.stream.kafka.bindings.input.consumer.configuration.max.poll.interval.ms=60000
app.preparation-worker.spring.cloud.stream.function.bindings.prepareExecutionJobs-in-0=input
app.preparation-worker.spring.cloud.stream.function.bindings.prepareExecutionJobs-out-0=output
app.preparation-worker.spring.cloud.stream.function.definition=prepareExecutionJobs

app.preparation-worker.mongodb.host=mongodb-0.mongodb-headless.database.svc.cluster.local
app.preparation-worker.mongodb.port=27017
app.preparation-worker.mongodb.database=coprs
app.preparation-worker.mongodb.username=${MONGO_USERNAME}
app.preparation-worker.mongodb.password=${MONGO_PASSWORD}

app.preparation-worker.metrics.mission=S3
app.preparation-worker.metrics.level=2
app.preparation-worker.metrics.addonName=ol2

app.preparation-worker.metadata.metadataHostname=rs-metadata-catalog-searchcontroller-svc:8080
app.preparation-worker.metadata.nbretry=3
app.preparation-worker.metadata.temporetryms=1000

app.preparation-worker.process.level=S3_L2
app.preparation-worker.process.mode=PROD
app.preparation-worker.process.hostname=s3-ol2-preparation-worker
app.preparation-worker.process.productType=S3_L1_NRT
app.preparation-worker.process.loglevelstdout=INFO
app.preparation-worker.process.loglevelstderr=INFO
app.preparation-worker.process.processingstation=S3__
app.preparation-worker.process.params.Processing_Mode=NRT
app.preparation-worker.process.params.Timeout=300
app.preparation-worker.process.mission=S3

app.preparation-worker.worker.diroftasktables=/app/tasktables/
app.preparation-worker.worker.maxnboftasktable=4
app.preparation-worker.worker.defaultfamily=BLANK
app.preparation-worker.worker.inputfamiliesstr=\\w{10}G:S3_GRANULES||\\w{10}X:S3_AUX||\\w{3}0\\w{6}(?!(G|X))\\w{1}:S3_L0||\\w{3}1\\w{6}(?!(G|X))\\w{1}:S3_L1_NRT||\\w{3}2\\w{6}(?!(G|X))\\w{1}:S3_L2_NRT
app.preparation-worker.worker.outputfamiliesstr=\\w{10}X:S3_AUX||\\w{3}0\\w{6}(?!(G|X))\\w{1}:S3_L0||\\w{3}1\\w{6}(?!(G|X))\\w{1}:S3_L1_NRT||\\w{3}2\\w{6}(?!(G|X))\\w{1}:S3_L2_NRT
app.preparation-worker.worker.product-mode=NRT
app.preparation-worker.worker.pathTaskTableXslt=/app/xslt/tasktable.xslt
app.preparation-worker.worker.primaryCheckMaxTimelifeS=900

app.preparation-worker.tasktable.routingKeyTemplate=$(product.productType)_$(product.satelliteId)
app.preparation-worker.tasktable.routing.OL_1_EFR____A=TaskTable_S3A_OL2_FR_06_18.xml
app.preparation-worker.tasktable.routing.OL_1_EFR____B=TaskTable_S3B_OL2_FR_06_18.xml
app.preparation-worker.tasktable.routing.OL_1_ERR____A=TaskTable_S3A_OL2_RR_06_18.xml
app.preparation-worker.tasktable.routing.OL_1_ERR____B=TaskTable_S3B_OL2_RR_06_18.xml

app.preparation-worker.s3-type-adapter.optionalOutputs.S3A_OL2_FR=OL_2_LFR___
app.preparation-worker.s3-type-adapter.optionalOutputs.S3A_OL2_RR=OL_2_LRR___
app.preparation-worker.s3-type-adapter.optionalOutputs.S3B_OL2_FR=OL_2_LFR___
app.preparation-worker.s3-type-adapter.optionalOutputs.S3B_OL2_RR=OL_2_LRR___
app.preparation-worker.s3-type-adapter.dyn-proc-params.facilityName=LN3
app.preparation-worker.s3-type-adapter.dyn-proc-params.hardwareName=O

## Housekeeping Service
app.housekeep.spring.cloud.stream.kafka.bindings.input.consumer.configuration.max.poll.records=1
app.housekeep.spring.cloud.stream.kafka.bindings.input.consumer.configuration.max.poll.interval.ms=60000
app.time.spring.integration.poller.fixed-rate=60s
app.time.spring.cloud.stream.kafka.bindings.input.consumer.configuration.max.poll.records=50
app.time.spring.cloud.stream.kafka.bindings.input.consumer.configuration.max.poll.interval.ms=600000


app.housekeep.spring.cloud.stream.function.bindings.houseKeepAppDataJobs-in-0=input
app.housekeep.spring.cloud.stream.function.bindings.houseKeepAppDataJobs-out-0=output
app.housekeep.spring.cloud.stream.function.definition=houseKeepAppDataJobs

app.housekeep.mongodb.host=mongodb-0.mongodb-headless.database.svc.cluster.local
app.housekeep.mongodb.port=27017
app.housekeep.mongodb.database=coprs
app.housekeep.mongodb.username=${MONGO_USERNAME}
app.housekeep.mongodb.password=${MONGO_PASSWORD}

app.housekeep.metadata.metadataHostname=rs-metadata-catalog-searchcontroller-svc:8080
app.housekeep.metadata.nbretry=3
app.housekeep.metadata.temporetryms=1000

app.housekeep.process.level=S3_L2
app.housekeep.process.mode=PROD
app.housekeep.process.hostname=s3-ol2-preparation-worker
app.housekeep.process.productType=S3_L1_NRT
app.housekeep.process.loglevelstdout=INFO
app.housekeep.process.loglevelstderr=INFO
app.housekeep.process.processingstation=S3__
app.housekeep.process.params.Processing_Mode=NRT
app.housekeep.process.params.Timeout=300
app.housekeep.process.mission=S3

app.housekeep.worker.diroftasktables=/app/tasktables/
app.housekeep.worker.maxnboftasktable=4
app.housekeep.worker.defaultfamily=BLANK
app.housekeep.worker.inputfamiliesstr=\\w{10}G:S3_GRANULES||\\w{10}X:S3_AUX||\\w{3}0\\w{6}(?!(G|X))\\w{1}:S3_L0||\\w{3}1\\w{6}(?!(G|X))\\w{1}:S3_L1_NRT||\\w{3}2\\w{6}(?!(G|X))\\w{1}:S3_L2_NRT
app.housekeep.worker.outputfamiliesstr=\\w{10}X:S3_AUX||\\w{3}0\\w{6}(?!(G|X))\\w{1}:S3_L0||\\w{3}1\\w{6}(?!(G|X))\\w{1}:S3_L1_NRT||\\w{3}2\\w{6}(?!(G|X))\\w{1}:S3_L2_NRT
app.housekeep.worker.product-mode=NRT
app.housekeep.worker.pathTaskTableXslt=/app/xslt/tasktable.xslt
app.housekeep.worker.primaryCheckMaxTimelifeS=900
app.housekeep.worker.maxAgeJobMs.waiting=604800000
app.housekeep.worker.maxAgeJobMs.dispatching=604800000
app.housekeep.worker.maxAgeJobMs.generating=604800000
app.housekeep.worker.maxAgeJobMs.terminated=604800000

app.housekeep.tasktable.routingKeyTemplate=$(product.productType)_$(product.satelliteId)
app.housekeep.tasktable.routing.OL_1_EFR____A=TaskTable_S3A_OL2_FR_06_18.xml
app.housekeep.tasktable.routing.OL_1_EFR____B=TaskTable_S3B_OL2_FR_06_18.xml
app.housekeep.tasktable.routing.OL_1_ERR____A=TaskTable_S3A_OL2_RR_06_18.xml
app.housekeep.tasktable.routing.OL_1_ERR____B=TaskTable_S3B_OL2_RR_06_18.xml

app.housekeep.s3-type-adapter.optionalOutputs.S3A_OL2_FR=OL_2_LFR___
app.housekeep.s3-type-adapter.optionalOutputs.S3A_OL2_RR=OL_2_LRR___
app.housekeep.s3-type-adapter.optionalOutputs.S3B_OL2_FR=OL_2_LFR___
app.housekeep.s3-type-adapter.optionalOutputs.S3B_OL2_RR=OL_2_LRR___
app.housekeep.s3-type-adapter.dyn-proc-params.facilityName=LN3
app.housekeep.s3-type-adapter.dyn-proc-params.hardwareName=O

app.execution-worker.spring.cloud.stream.function.bindings.executeJob-in-0=input
app.execution-worker.spring.cloud.stream.function.bindings.executeJob-out-0=output
app.execution-worker.spring.cloud.stream.function.definition=executeJob
app.execution-worker.spring.cloud.stream.kafka.bindings.input.consumer.configuration.max.poll.records=1
app.execution-worker.spring.cloud.stream.kafka.bindings.input.consumer.configuration.max.poll.interval.ms=3600000

app.execution-worker.process.level=S3_L2
app.execution-worker.process.hostname=${HOSTNAME}
app.execution-worker.process.workingDir=/data/localWD
app.execution-worker.process.tm-proc-stop-s=300
app.execution-worker.process.tm-proc-one-task-s=600
app.execution-worker.process.tm-proc-all-tasks-s=3600
app.execution-worker.process.tm-proc-check-stop-s=60
app.execution-worker.process.size-batch-upload=10
app.execution-worker.process.size-batch-download=10
app.execution-worker.process.wap-nb-max-loop=24
app.execution-worker.process.wap-tempo-s=20
app.execution-worker.process.path-job-order-xslt=/app/joborder/jobOrder.xslt
app.execution-worker.dev.stepsActivation.download=true
app.execution-worker.dev.stepsActivation.upload=true
app.execution-worker.dev.stepsActivation.erasing=true

# Output Product Estimation 
app.execution-worker.process.productTypeEstimationEnabled=true

# Use latest inputs only (see rs-1034)
app.preparation-worker.worker.useLatestOnly=true
app.housekeep.worker.useLatestOnly=true
 

# Mandatory Deployer Settings
deployer.time.kubernetes.imagePullPolicy=IfNotPresent
deployer.message-filter.kubernetes.imagePullPolicy=IfNotPresent
deployer.preparation-worker.kubernetes.imagePullPolicy=Always
deployer.preparation-worker.kubernetes.imagePullSecrets=spring-cloud-dataflow-registry-dockersecret
deployer.housekeep.kubernetes.imagePullPolicy=Always
deployer.housekeep.kubernetes.imagePullSecrets=spring-cloud-dataflow-registry-dockersecret
deployer.execution-worker.kubernetes.imagePullPolicy=Always
deployer.execution-worker.kubernetes.imagePullSecrets=spring-cloud-dataflow-registry-dockersecret

# Liveness Probe
deployer.*.kubernetes.namespace=processing
deployer.*.kubernetes.livenessProbeDelay=10
deployer.*.kubernetes.livenessProbePeriod=120
deployer.*.kubernetes.livenessProbeTimeout=20
deployer.*.kubernetes.livenessProbePath=/actuator/health/liveness
deployer.*.kubernetes.livenessProbePort=8080

# Readiness Probe
deployer.*.kubernetes.readinessProbeDelay=10
deployer.*.kubernetes.readinessProbePeriod=120
deployer.*.kubernetes.readinessProbeTimeout=20
deployer.*.kubernetes.readinessProbePath=/actuator/health/readiness
deployer.*.kubernetes.readinessProbePort=8080

deployer.*.kubernetes.maxTerminatedErrorRestarts=20

# Additional Deployer Settings
deployer.*.kubernetes.environmentVariables=JAVA_TOOL_OPTIONS=-Xmx512m

deployer.preparation-worker.kubernetes.secretKeyRefs=[{ envVarName: 'MONGO_USERNAME', secretName: 'mongopreparation', dataKey: 'USERNAME' },{ envVarName: 'MONGO_PASSWORD', secretName: 'mongopreparation', dataKey: 'PASSWORD' }]
deployer.preparation-worker.kubernetes.volumeMounts=[{name: tasktables, mountPath: '/app/tasktables'},{name: tasktablexslt, mountPath: '/app/xslt'}] 
deployer.preparation-worker.kubernetes.volumes=[{name: tasktablexslt, configMap: {name: s3-ol2-tasktablexslt, items: [{key: 'tasktable.xslt', path: 'tasktable.xslt'}]}},{name: tasktables, configMap: {name: s3-ol2-tasktables, items: [{key: 'TaskTable_S3A_OL2_FR_06_18.xml', path: 'TaskTable_S3A_OL2_FR_06_18.xml'},{key: 'TaskTable_S3B_OL2_FR_06_18.xml', path: 'TaskTable_S3B_OL2_FR_06_18.xml'},{key: 'TaskTable_S3A_OL2_RR_06_18.xml', path: 'TaskTable_S3A_OL2_RR_06_18.xml'},{key: 'TaskTable_S3B_OL2_RR_06_18.xml', path: 'TaskTable_S3B_OL2_RR_06_18.xml'}]}}] 

deployer.housekeep.kubernetes.secretKeyRefs=[{ envVarName: 'MONGO_USERNAME', secretName: 'mongopreparation', dataKey: 'USERNAME' },{ envVarName: 'MONGO_PASSWORD', secretName: 'mongopreparation', dataKey: 'PASSWORD' }]
deployer.housekeep.kubernetes.volumeMounts=[{name: tasktables, mountPath: '/app/tasktables'},{name: tasktablexslt, mountPath: '/app/xslt'}] 
deployer.housekeep.kubernetes.volumes=[{name: tasktablexslt, configMap: {name: s3-ol2-tasktablexslt, items: [{key: 'tasktable.xslt', path: 'tasktable.xslt'}]}},{name: tasktables, configMap: {name: s3-ol2-tasktables, items: [{key: 'TaskTable_S3A_OL2_FR_06_18.xml', path: 'TaskTable_S3A_OL2_FR_06_18.xml'},{key: 'TaskTable_S3B_OL2_FR_06_18.xml', path: 'TaskTable_S3B_OL2_FR_06_18.xml'},{key: 'TaskTable_S3A_OL2_RR_06_18.xml', path: 'TaskTable_S3A_OL2_RR_06_18.xml'},{key: 'TaskTable_S3B_OL2_RR_06_18.xml', path: 'TaskTable_S3B_OL2_RR_06_18.xml'}]}}] 

deployer.execution-worker.kubernetes.secretKeyRefs=[{ envVarName: 'OBS_USERNAME', secretName: 'obs', dataKey: 'USER_ID' },{ envVarName: 'OBS_PASSWORD', secretName: 'obs', dataKey: 'USER_SECRET' }]
deployer.execution-worker.kubernetes.podSecurityContext={runAsUser: 0, fsGroup: 0}
deployer.execution-worker.kubernetes.volumeMounts=[{name: joborderxslt, mountPath: '/app/joborder'}, { name: 's3-upload-cache', mountPath: '/opt/s3/uploadCache'}] 
deployer.execution-worker.kubernetes.volumes=[{name: joborderxslt, configMap: {name: s3-ol2-joborderxslt, items: [{key: 'jobOrder.xslt', path: 'jobOrder.xslt'}]}}, { name: 's3-upload-cache', emptyDir: { medium: 'Memory', sizeLimit: '1500Mi' }}]

#Node affinity configuration
deployer.*.kubernetes.affinity.nodeAffinity={ requiredDuringSchedulingIgnoredDuringExecution: { nodeSelectorTerms: [ { matchExpressions: [ { key: 'node-role.kubernetes.io/processing', operator: 'In', values: 'common'}]}]}}

# OBS properties
app.*.obs.user-id=${OBS_USERNAME}
app.*.obs.user-secret=${OBS_PASSWORD}
app.*.obs.endpoint=http://oss.eu-west-0.prod-cloud-ocb.orange-business.com
app.*.obs.endpoint-region=eu-west-0
app.*.obs.disable-chunked-encoding=false
app.*.obs.bucket.failed-workdir=ops-rs-failed-workdir

## Input buckets
# rs-l0 will be replaced by rs-s3-l0-isp
app.*.obs.bucket.s3-l1-nrt=ops-rs-s3-l1-nrt
# rs-aux will be replaced ops-rs-s3-aux
app.*.obs.bucket.s3-aux=ops-rs-aux

## Output buckets
app.*.obs.bucket.s3-l2-nrt=ops-rs-s3-l2-nrt
app.*.obs.bucket.s3-l2-nrt-zip=ops-rs-s3-l2-nrt-zip

